{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Challenge Data Analytics (Supervised regression task) Python Code Key Steps\n",
    "============================================\n",
    "\n",
    "Overall, there are four parts of this analysis:\n",
    "1. Data Exploratory; \n",
    "2. Data Engineering; \n",
    "3. Finalizing Training Dataset; \n",
    "4. Modeling and Evaluation\n",
    "\n",
    "Assumptions for the analysis:<br>\n",
    "1. Assume measurement values less than or equal to zero are invalid;\n",
    "2. Assume there is start up period of the process, which last for 60s;\n",
    "3. Assume only focus on raw material properties and controlled variables based on project goal.\n",
    "\n",
    "\n",
    "[1. Data Exploratory](#1.Data Exploratory)\n",
    "--------------------\n",
    "Have an overview of the dataset, get the idea what to do in next step Data Engineering.\n",
    "\n",
    "[2. Data Engineering](#2.Data Engineering)\n",
    "--------------------\n",
    "[2.1 Missing value](#Missing value):<br> There's no missing values.<br>\n",
    "[2.2 Outlier](#Outlier):<br> Remove invalid data points, including measurement values less than or equal to zero, values might be collected during the start up period (assume first 60s), abnormal changed values. And then conduct [moving average (30s window)](#smooth noise) to remove random noise.<br>\n",
    "[2.3 Variable type](#Variable type): <br> Variables are all continous numerical data, so there is no need to do extra processing.<br>\n",
    "[2.4 Scaling](#Scaling): <br> Although normalizing features is a general requirement for many machine learning algorithms, it's inproper to do normalization without background knowledge of input variables. Therefore, input variables are not normalized.<br>\n",
    "[2.5 Multi-collinearity](#Multi-collinearity): <br> There is severe multi-collinearity problem among the input variables for stage1 and stage2, especially for material property variables, which should be noticed while modeling.<br>\n",
    "Rule of thumb: VIF >10, high multi-collinearity<br>\n",
    "[2.6 Feature transformation](#Feature transformation): <br> Not be able to do feature transformation (generate new meaningful features) without background knowledge of input variables.\n",
    "\n",
    "[3. Finalizing Training Dataset](#3.Finalizing Training Dataset)\n",
    "--------------------\n",
    "Prepare training dataset for modeling:<br>\n",
    "Input variables: <br>\n",
    "Stage 1:<br>\n",
    "Machine1.RawMaterial.Property1<br>\n",
    "Machine1.RawMaterial.Property2<br>\n",
    "Machine1.RawMaterial.Property3<br>\n",
    "Machine1.RawMaterial.Property4<br>\n",
    "Machine1.Zone1Temperature.C.Actual<br>\n",
    "Machine1.Zone2Temperature.C.Actual<br>\n",
    "Machine1.MotorRPM.C.Actual<br>\n",
    "Machine1.ExitZoneTemperature.C.Actual<br>\n",
    "Machine2.RawMaterial.Property1<br>\n",
    "Machine2.RawMaterial.Property2<br>\n",
    "Machine2.RawMaterial.Property3<br>\n",
    "Machine2.RawMaterial.Property4<br>\n",
    "Machine2.Zone1Temperature.C.Actual<br>\n",
    "Machine2.Zone2Temperature.C.Actual<br>\n",
    "Machine2.MotorRPM.C.Actual<br>\n",
    "Machine2.ExitZoneTemperature.C.Actual<br>\n",
    "Machine3.RawMaterial.Property1<br>\n",
    "Machine3.RawMaterial.Property2<br>\n",
    "Machine3.RawMaterial.Property3<br>\n",
    "Machine3.RawMaterial.Property4<br>\n",
    "Machine3.Zone1Temperature.C.Actual<br>\n",
    "Machine3.Zone2Temperature.C.Actual<br>\n",
    "Machine3.MotorRPM.C.Actual<br>\n",
    "Machine3.ExitZoneTemperature.C.Actual<br>\n",
    "FirstStage.CombinerOperation.Temperature3.C.Actual<br>\n",
    "\n",
    "Stage 2:\n",
    "Machine1.RawMaterial.Property1<br>\n",
    "Machine1.RawMaterial.Property2<br>\n",
    "Machine1.RawMaterial.Property3<br>\n",
    "Machine1.RawMaterial.Property4<br>\n",
    "Machine1.Zone1Temperature.C.Actual<br>\n",
    "Machine1.Zone2Temperature.C.Actual<br>\n",
    "Machine1.MotorRPM.C.Actual<br>\n",
    "Machine1.ExitZoneTemperature.C.Actual<br>\n",
    "Machine2.RawMaterial.Property1<br>\n",
    "Machine2.RawMaterial.Property2<br>\n",
    "Machine2.RawMaterial.Property3<br>\n",
    "Machine2.RawMaterial.Property4<br>\n",
    "Machine2.Zone1Temperature.C.Actual<br>\n",
    "Machine2.Zone2Temperature.C.Actual<br>\n",
    "Machine2.MotorRPM.C.Actual<br>\n",
    "Machine2.ExitZoneTemperature.C.Actual<br>\n",
    "Machine3.RawMaterial.Property1<br>\n",
    "Machine3.RawMaterial.Property2<br>\n",
    "Machine3.RawMaterial.Property3<br>\n",
    "Machine3.RawMaterial.Property4<br>\n",
    "Machine3.Zone1Temperature.C.Actual<br>\n",
    "Machine3.Zone2Temperature.C.Actual<br>\n",
    "Machine3.MotorRPM.C.Actual<br>\n",
    "Machine3.ExitZoneTemperature.C.Actual<br> \n",
    "FirstStage.CombinerOperation.Temperature3.C.Actual  \n",
    "Machine4.Temperature1.C.Actual  \n",
    "Machine4.Temperature2.C.Actual  \n",
    "Machine4.Pressure.C.Actual  \n",
    "Machine4.Temperature4.C.Actual  \n",
    "Machine4.Temperature5.C.Actual<br>\n",
    "Machine5.Temperature1.C.Actual<br> \n",
    "Machine5.Temperature2.C.Actual  \n",
    "Machine5.Temperature3.C.Actual  \n",
    "Machine5.Temperature4.C.Actual<br> \n",
    "Machine5.Temperature5.C.Actual<br> \n",
    "Machine5.Temperature6.C.Actual  \n",
    "\n",
    "\n",
    "Output variables:<br>\n",
    "Stage1.Measurement%d.DV_ErrorRate or Stage1.Output.Measurement%d.U.Actual <br>\n",
    "Stage2.Measurement%d.DV_ErrorRate or Stage2.Output.Measurement%d.U.Actual\n",
    "\n",
    "[4. Modeling and Evaluation](#4.Modeling and Evaluation)\n",
    "--------------------\n",
    "Including model building and model performance evaluation. <br>\n",
    "\n",
    "4.1 Model building:  <br>\n",
    "Linear Regression and Bayesian Ridge Regression are selected for modeling. Since input variables with narrow range might not provide enough information to model building, complicated models have not been applied.\n",
    "\n",
    "4.2 Model performance evaluation:  <br>\n",
    "(1) Mean Absolute Error, Mean Squared Error, Root Mean Squared Error are used to evaluate model performance.<br>\n",
    "(2) Performance of Bayesian Ridge Regression model is similar with performance of Linear Regression model.<br>\n",
    "(3) Model performance differ from measurement to measurement, and from stage to stage (more details refer to corresponding bar charts of [Linear Regression Model Performance](#lr performance) and [Bayesian Ridge Regression Model Performance](#brr performance)<br>\n",
    "(4) Bayesian Ridge Regression model give shrinkage to those coefficients of high VIF variables. [Take Measurement0 at Stage1 for example](#Coefficients)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from statistics import mode\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-bright\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized functions for data processing\n",
    "from DataProcessFunction import error_rate\n",
    "from DataProcessFunction import clean_outlier\n",
    "from DataProcessFunction import vif_cal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RawData = pd.read_csv('RawData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.Data Exploratory'></a>\n",
    "### 1.Data Exploratory\n",
    "Have a overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = RawData # Save a copy before editing to prevent changing the original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Categorize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['ID'] = Data.reset_index().index # Add rows' ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AmbientConditions_cols = [col for col in Data.columns if 'AmbientConditions' in col]\n",
    "Machine1_cols = [col for col in Data.columns if 'Machine1' in col]\n",
    "Machine2_cols = [col for col in Data.columns if 'Machine2' in col]\n",
    "Machine3_cols = [col for col in Data.columns if 'Machine3' in col]\n",
    "Combiner_cols = [col for col in Data.columns if 'Combiner' in col]\n",
    "Stage1_cols = [col for col in Data.columns if 'Stage1' in col]\n",
    "Machine4_cols = [col for col in Data.columns if 'Machine4' in col]\n",
    "Machine5_cols = [col for col in Data.columns if 'Machine5' in col]\n",
    "Stage2_cols = [col for col in Data.columns if 'Stage2' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AmbientConditions_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine1_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combiner_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stage1_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine4_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stage2_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Check Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[[\"time_stamp\"]] # Check sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Data[\"time_stamp\"]) # Check column type, shows not the real Timestamp type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Define input variables\n",
    "Based on project goal and process features, select raw material properties and controlled variables as input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine1_C_cols = [col for col in Machine1_cols if '.U.' not in col]\n",
    "Machine2_C_cols = [col for col in Machine2_cols if '.U.' not in col]\n",
    "Machine3_C_cols = [col for col in Machine3_cols if '.U.' not in col]\n",
    "Combiner_C_cols = [col for col in Combiner_cols if '.U.' not in col]\n",
    "Machine4_C_cols = [col for col in Machine4_cols if '.U.' not in col]\n",
    "Machine5_C_cols = [col for col in Machine5_cols if '.U.' not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_cols_Stage1 = Machine1_C_cols+Machine2_C_cols+Machine3_C_cols+Combiner_C_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_cols_Stage2 = Machine1_C_cols+Machine2_C_cols+Machine3_C_cols+Combiner_C_cols+Machine4_C_cols+Machine5_C_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Define output variables\n",
    "Based on project goal, use error versus setpoint as dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[Stage1_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data[Stage2_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(15,1,figsize=(30,150))\n",
    "\n",
    "for i in range(15):\n",
    "    ax[i].plot(Data.loc[:, 'Stage1.Output.Measurement%d.U.Actual'% (i)],\n",
    "               marker='.', linestyle=':', linewidth=0.5, label='Actual')\n",
    "    ax[i].plot(Data.loc[:, 'Stage1.Output.Measurement%d.U.Setpoint'% (i)],\n",
    "            marker='o', markersize=0.5, linestyle='-', label='Setpoint')\n",
    "    ax[i].set_ylabel('Stage1.Output.Measurement%d'% (i))\n",
    "    ax[i].set_xlabel('Time (Sec)')\n",
    "    ax[i].legend(loc='upper right');\n",
    "\n",
    "# Have a overview of Stage1.Outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(15,1,figsize=(30,150))\n",
    "\n",
    "for i in range(15):\n",
    "    ax[i].plot(Data.loc[:, 'Stage2.Output.Measurement%d.U.Actual'% (i)],\n",
    "               marker='.', linestyle=':', linewidth=0.5, label='Actual')\n",
    "    ax[i].plot(Data.loc[:, 'Stage2.Output.Measurement%d.U.Setpoint'% (i)],\n",
    "            marker='o', markersize=0.5, linestyle='-', label='Setpoint')\n",
    "    ax[i].set_ylabel('Stage2.Output.Measurement%d'% (i))\n",
    "    ax[i].set_xlabel('Time (Sec)')\n",
    "    ax[i].legend(loc='upper right');\n",
    "\n",
    "# Have a overview of Stage2.Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note1: Summary from the output measurement plots above\n",
    "\n",
    "1.Most of the setpoint values at stage1 are constant, except several ones(0) around 4000s. If these points are outliers due to measurement error, they should be removed from training dataset. Also, constant setpoint values would avoid ratio (error versus setpoints) issues while training models.\n",
    "\n",
    "2.Some of the actual measurement values are equal or less than 0, if these points are outliers due to measurement error or start up period, they should be removed from training dataset.\n",
    "\n",
    "3.Several stage1 actual values around 10000s changed suddenly in all 15 measurements. Assumed these points are outliers due to measurement error, and they should be removed from training dataset.\n",
    "\n",
    "4.There is not obvious trend from the plots. Time elements would not be considered while modeling for temporary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use error versus setpoint as dependent variables \n",
    "(final value rounded to 3 decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    Data[\"Stage1.Measurement%d.ErrorRate\"%(i)]= error_rate(Data,\"Stage1.Output.Measurement%d.U.Actual\"%(i),\"Stage1.Output.Measurement%d.U.Setpoint\"%(i))\n",
    "    Data[\"Stage2.Measurement%d.ErrorRate\"%(i)]= error_rate(Data,\"Stage2.Output.Measurement%d.U.Actual\"%(i),\"Stage2.Output.Measurement%d.U.Setpoint\"%(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.Data Engineering'></a>\n",
    "### 2. Data Engineering\n",
    "Dealing with missing value, outlier, variable type, scaling, multi-collinearity, feature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Missing value'></a>\n",
    "#### 2.1 Check Missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_cols = [col for col in Data.columns if 'ErrorRate' not in col]\n",
    "for col in Original_cols:\n",
    "    if Data[col].isna().sum()>0:\n",
    "        print(col+\":%d\"%(Data[col].isna().sum()))\n",
    "# No missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Outlier'></a>\n",
    "#### 2.2 Check Outlier\n",
    "Refer to Note1, remove invalid rows from traning set for specific output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use dictionary to store training data set for each measurement\n",
    "Data.stage1 = {} \n",
    "Data.stage2 = {} \n",
    "\n",
    "# Refer to Note1.2, assumed output values less than or equal to 0 are invalid datapoints\n",
    "for i in range(15):\n",
    "    Data.stage1[\"Measurement%d\"%(i)] = clean_outlier(Data,\"Stage1.Output.Measurement%d.U.Actual\"%(i))\n",
    "    Data.stage2[\"Measurement%d\"%(i)] = clean_outlier(Data,\"Stage2.Output.Measurement%d.U.Actual\"%(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to Note1.1,get corresponding row ID \n",
    "invalid_ID_1 = list(Data[Data['Stage1.Output.Measurement0.U.Setpoint'] < mode(Data['Stage1.Output.Measurement0.U.Setpoint'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to Note1.3,get corresponding row ID \n",
    "invalid_ID_2 = list(Data[Data['Stage1.Output.Measurement0.U.Actual'] > mode(Data['Stage1.Output.Measurement0.U.Setpoint'])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid data points according to Note1.1 and Note1.3\n",
    "invalid_ID = invalid_ID_1 + invalid_ID_2\n",
    "for i in range(15):\n",
    "    for j in invalid_ID:\n",
    "        Data.stage1[\"Measurement%d\"%(i)] = Data.stage1[\"Measurement%d\"%(i)][Data.stage1[\"Measurement%d\"%(i)]['ID']!=j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid data points during start up period (<60s) at stage2\n",
    "for i in range(15):\n",
    "    Data.stage2[\"Measurement%d\"%(i)] = Data.stage2[\"Measurement%d\"%(i)][Data.stage2[\"Measurement%d\"%(i)]['ID']>60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Outputs Plot\n",
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(15,1,figsize=(30,150))\n",
    "\n",
    "for i in range(15):\n",
    "    ax[i].plot(Data.stage1[\"Measurement%d\"%(i)]['ID'],Data.stage1[\"Measurement%d\"%(i)]['Stage1.Output.Measurement%d.U.Actual'% (i)],\n",
    "               marker='.', linestyle=':', linewidth=0.5, label='Actual')\n",
    "    ax[i].plot(Data.stage1[\"Measurement%d\"%(i)]['ID'],Data.stage1[\"Measurement%d\"%(i)]['Stage1.Output.Measurement%d.U.Setpoint'% (i)],\n",
    "            marker='o', markersize=0.5, linestyle=':', label='Setpoint')\n",
    "    ax[i].set_ylabel('Stage1.Output.Measurement%d'% (i))\n",
    "    ax[i].set_xlabel('Time (Sec)')\n",
    "    ax[i].legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(15,1,figsize=(30,150))\n",
    "\n",
    "for i in range(15):\n",
    "    ax[i].plot(Data.stage2[\"Measurement%d\"%(i)]['ID'],Data.stage2[\"Measurement%d\"%(i)]['Stage2.Output.Measurement%d.U.Actual'% (i)],\n",
    "               marker='.', linestyle=':', linewidth=0.5, label='Actual')\n",
    "    ax[i].plot(Data.stage2[\"Measurement%d\"%(i)]['ID'],Data.stage2[\"Measurement%d\"%(i)]['Stage2.Output.Measurement%d.U.Setpoint'% (i)],\n",
    "            marker='o', markersize=0.5, linestyle=':', label='Setpoint')\n",
    "    ax[i].set_ylabel('Stage2.Output.Measurement%d'% (i))\n",
    "    ax[i].set_xlabel('Time (Sec)')\n",
    "    ax[i].legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing noise (assumed those are random noise) with 60s window\n",
    "Data.stage1_smooth = Data.stage1.copy()\n",
    "Data.stage2_smooth = Data.stage2.copy()\n",
    "for i in range(15):    \n",
    "    Data.stage1_smooth[\"Measurement%d\"%(i)] = Data.stage1_smooth[\"Measurement%d\"%(i)].set_index(pd.DatetimeIndex(Data.stage1_smooth[\"Measurement%d\"%(i)]['time_stamp']))\n",
    "    Data.stage1_smooth[\"Measurement%d\"%(i)]['Stage1.Output.Measurement%d.U.Actual'% (i)] = Data.stage1_smooth[\"Measurement%d\"%(i)]['Stage1.Output.Measurement%d.U.Actual'% (i)].rolling('30s').mean()\n",
    "    Data.stage2_smooth[\"Measurement%d\"%(i)] = Data.stage2_smooth[\"Measurement%d\"%(i)].set_index(pd.DatetimeIndex(Data.stage2_smooth[\"Measurement%d\"%(i)]['time_stamp']))\n",
    "    Data.stage2_smooth[\"Measurement%d\"%(i)]['Stage2.Output.Measurement%d.U.Actual'% (i)] = Data.stage2_smooth[\"Measurement%d\"%(i)]['Stage2.Output.Measurement%d.U.Actual'% (i)].rolling('30s').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='smooth noise'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Outputs Plot after smoothing\n",
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(15,1,figsize=(30,150))\n",
    "\n",
    "for i in range(15):\n",
    "    ax[i].plot(Data.stage1[\"Measurement%d\"%(i)]['ID'],Data.stage1[\"Measurement%d\"%(i)]['Stage1.Output.Measurement%d.U.Actual'% (i)],\n",
    "               marker='.', linestyle=':', linewidth=0.5, label='Actual Measurement before Smoothing')\n",
    "    ax[i].plot(Data.stage1[\"Measurement%d\"%(i)]['ID'],Data.stage1[\"Measurement%d\"%(i)]['Stage1.Output.Measurement%d.U.Setpoint'% (i)],\n",
    "            marker='o', markersize=0.5, linestyle=':', label='Setpoint')\n",
    "    ax[i].plot(Data.stage1_smooth[\"Measurement%d\"%(i)]['ID'],Data.stage1_smooth[\"Measurement%d\"%(i)]['Stage1.Output.Measurement%d.U.Actual'% (i)],\n",
    "            marker='o', markersize=0.5, linestyle=':', label='Actual Measurement after Smoothing(30s)')\n",
    "    ax[i].set_ylabel('Stage1.Output.Measurement%d'% (i))\n",
    "    ax[i].set_xlabel('Time (Sec)')\n",
    "    ax[i].legend(loc='upper right');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(15,1,figsize=(30,150))\n",
    "\n",
    "for i in range(15):\n",
    "    ax[i].plot(Data.stage2[\"Measurement%d\"%(i)]['ID'],Data.stage2[\"Measurement%d\"%(i)]['Stage2.Output.Measurement%d.U.Actual'% (i)],\n",
    "               marker='.', linestyle=':', linewidth=0.5, label='Actual Measurement before Smoothing')\n",
    "    ax[i].plot(Data.stage2[\"Measurement%d\"%(i)]['ID'],Data.stage2[\"Measurement%d\"%(i)]['Stage2.Output.Measurement%d.U.Setpoint'% (i)],\n",
    "            marker='o', markersize=0.5, linestyle=':', label='Setpoint')\n",
    "    ax[i].plot(Data.stage2_smooth[\"Measurement%d\"%(i)]['ID'],Data.stage2_smooth[\"Measurement%d\"%(i)]['Stage2.Output.Measurement%d.U.Actual'% (i)],\n",
    "            marker='o', markersize=0.5, linestyle=':', label='Actual Measurement after Smoothing(30s)')\n",
    "    ax[i].set_ylabel('Stage2.Output.Measurement%d'% (i))\n",
    "    ax[i].set_xlabel('Time (Sec)')\n",
    "    ax[i].legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15): \n",
    "    \n",
    "    Data.stage1_smooth[\"Measurement%d\"%(i)] = Data.stage1_smooth[\"Measurement%d\"%(i)][Data.stage1_smooth[\"Measurement%d\"%(i)]['Stage1.Output.Measurement%d.U.Actual'% (i)].notnull()]\n",
    "    Data.stage2_smooth[\"Measurement%d\"%(i)] = Data.stage2_smooth[\"Measurement%d\"%(i)][Data.stage2_smooth[\"Measurement%d\"%(i)]['Stage2.Output.Measurement%d.U.Actual'% (i)].notnull()]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Variable type'></a>\n",
    "#### 2.3 Check variable type\n",
    "Independent variables are all continous numerical variable, no need to do extra processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Scaling'></a>\n",
    "#### 2.4 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check range of input variables\n",
    "Data.stage1_smooth[\"Measurement13\"][C_cols_Stage2].describe() \n",
    "# Scales differs a lot among input variables\n",
    "# However, input variables don't vary a lot, which won't provide rich info to the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note2: Summary from the input variables descriptive info above\n",
    "\n",
    "1.Scales differs a lot among input variables.\n",
    "\n",
    "2.Normalize features is important while comparing measurements that have different units, also a general requirement for many machine learning algorithms.\n",
    "\n",
    "3.However, based on use cases, it might not make sense to normalize features.\n",
    "\n",
    "4.Also, it's inproper to do normalization without background knowledge of input variables.\n",
    "\n",
    "5.Therefore, these input variables would not be normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Multi-collinearity'></a>\n",
    "#### 2.5 Multi-collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C_cols_Stage1_smallVif=vif_cal(Data.stage1_smooth[\"Measurement0\"][C_cols_Stage1]) \n",
    "# There is not severe multi-collinearity problem among the control input variables for stage1\n",
    "# Although \"Machine3.MotorRPM.C.Actual\" might get a bit higher value of VIF, which should be noticed while modeling\n",
    "# Rule of thumb: VIF >10, high multi-collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_cols_Stage2_smallVif = vif_cal(Data.stage2_smooth[\"Measurement0\"][C_cols_Stage2])\n",
    "# There is severe multi-collinearity problem among the control input variables for stage2, which should be noticed while modeling\n",
    "# Rule of thumb: VIF >10, high multi-collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Feature transformation'></a>\n",
    "#### 2.6 Feature Transformation\n",
    "Not able to do feature transformation without background knowledge of input variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.Finalizing Training Dataset'></a>\n",
    "### 3. Finalizing Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Variables: C_cols_Stage1 / C_cols_Stage1_smallVif, C_cols_Stage2 / C_cols_Stage2_smallVif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    Data.stage1_smooth[\"Measurement%d\"%(i)].reset_index(drop=True, inplace=True)\n",
    "    Data.stage2_smooth[\"Measurement%d\"%(i)].reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Variables: Stage1.Measurement%d.DV_ErrorRate / Stage1.Output.Measurement%d.U.Actual, Stage2.Measurement%d.DV_ErrorRate / Stage2.Output.Measurement%d.U.Actual\n",
    "for i in range(15):\n",
    "    Data.stage1_smooth[\"Measurement%d\"%(i)][\"Stage1.Measurement%d.DV_ErrorRate\"%(i)] = error_rate(Data.stage1_smooth[\"Measurement%d\"%(i)],\"Stage1.Output.Measurement%d.U.Actual\"%(i),\"Stage1.Output.Measurement%d.U.Setpoint\"%(i))\n",
    "    Data.stage2_smooth[\"Measurement%d\"%(i)][\"Stage2.Measurement%d.DV_ErrorRate\"%(i)] = error_rate(Data.stage2_smooth[\"Measurement%d\"%(i)],\"Stage2.Output.Measurement%d.U.Actual\"%(i),\"Stage2.Output.Measurement%d.U.Setpoint\"%(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingSet_stage1 = {} \n",
    "TrainingSet_stage2 = {} \n",
    "for i in range(15):\n",
    "    df1=Data.stage1_smooth[\"Measurement%d\"%(i)][[\"Stage1.Measurement%d.DV_ErrorRate\"%(i),\"Stage1.Output.Measurement%d.U.Actual\"%(i)]]\n",
    "    \n",
    "    df2 =Data.stage1_smooth[\"Measurement%d\"%(i)][C_cols_Stage1]\n",
    "    df3=Data.stage2_smooth[\"Measurement%d\"%(i)][[\"Stage2.Measurement%d.DV_ErrorRate\"%(i),\"Stage2.Output.Measurement%d.U.Actual\"%(i)]]\n",
    "    df4 = Data.stage2_smooth[\"Measurement%d\"%(i)][C_cols_Stage2]\n",
    "    TrainingSet_stage1[\"Measurement%d\"%(i)]=pd.concat([df1, df2], axis=1)\n",
    "    TrainingSet_stage2[\"Measurement%d\"%(i)]=pd.concat([df3, df4], axis=1)\n",
    "    \n",
    "    TrainingSet_stage1[\"Measurement%d\"%(i)].to_csv('TrainingSet_stage1_Measurement%d.csv'%(i),index=False)\n",
    "    TrainingSet_stage2[\"Measurement%d\"%(i)].to_csv('TrainingSet_stage2_Measurement%d.csv'%(i),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.Modeling and Evaluation'></a>\n",
    "### 4. Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Train-test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = {}\n",
    "X_test = {}\n",
    "y_train = {}\n",
    "y_test = {}\n",
    "X = {}\n",
    "y = {}\n",
    "for i in range(15):\n",
    "    X[\"stage1Measurement%d\"%(i)] = TrainingSet_stage1[\"Measurement%d\"%(i)][C_cols_Stage1].values\n",
    "    y[\"stage1Measurement%d\"%(i)] = TrainingSet_stage1[\"Measurement%d\"%(i)][\"Stage1.Output.Measurement%d.U.Actual\"%(i)].values\n",
    "    X_train[\"stage1Measurement%d\"%(i)],X_test[\"stage1Measurement%d\"%(i)],y_train[\"stage1Measurement%d\"%(i)],y_test[\"stage1Measurement%d\"%(i)] = train_test_split(X[\"stage1Measurement%d\"%(i)],y[\"stage1Measurement%d\"%(i)],test_size=0.2,random_state=0)\n",
    "    \n",
    "    X[\"stage2Measurement%d\"%(i)] = TrainingSet_stage2[\"Measurement%d\"%(i)][C_cols_Stage2].values\n",
    "    y[\"stage2Measurement%d\"%(i)] = TrainingSet_stage2[\"Measurement%d\"%(i)][\"Stage2.Output.Measurement%d.U.Actual\"%(i)].values\n",
    "    X_train[\"stage2Measurement%d\"%(i)],X_test[\"stage2Measurement%d\"%(i)],y_train[\"stage2Measurement%d\"%(i)],y_test[\"stage2Measurement%d\"%(i)] = train_test_split(X[\"stage2Measurement%d\"%(i)],y[\"stage2Measurement%d\"%(i)],test_size=0.2,random_state=0)\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_stage1 = {} # Model\n",
    "lr_stage2 = {}\n",
    "coeff_lr_stage1 = {} # Coefficient\n",
    "coeff_lr_stage2 = {}\n",
    "for i in range(15):\n",
    "    lr_stage1[\"Measurement%d\"%(i)] = LinearRegression()\n",
    "    lr_stage1[\"Measurement%d\"%(i)].fit(X_train[\"stage1Measurement%d\"%(i)], y_train[\"stage1Measurement%d\"%(i)])\n",
    "    \n",
    "    lr_stage2[\"Measurement%d\"%(i)] = LinearRegression()\n",
    "    lr_stage2[\"Measurement%d\"%(i)].fit(X_train[\"stage2Measurement%d\"%(i)], y_train[\"stage2Measurement%d\"%(i)])\n",
    "    \n",
    "    coeff_lr_stage1[\"Measurement%d\"%(i)] = pd.DataFrame(lr_stage1[\"Measurement%d\"%(i)].coef_, TrainingSet_stage1[\"Measurement%d\"%(i)][C_cols_Stage1].columns, columns=['Coefficient']) \n",
    "    coeff_lr_stage2[\"Measurement%d\"%(i)] = pd.DataFrame(lr_stage2[\"Measurement%d\"%(i)].coef_, TrainingSet_stage2[\"Measurement%d\"%(i)][C_cols_Stage2].columns, columns=['Coefficient'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stage1 = {} # Predicted value\n",
    "y_pred_stage2 = {}\n",
    "y_actual_pred_stage1 = {} # Compare Actual value and Predicted value\n",
    "y_actual_pred_stage2 = {}\n",
    "\n",
    "for i in range(15):\n",
    "    y_pred_stage1[\"Measurement%d\"%(i)] = lr_stage1[\"Measurement%d\"%(i)].predict(X_test[\"stage1Measurement%d\"%(i)])\n",
    "    y_actual_pred_stage1[\"Measurement%d\"%(i)] = pd.DataFrame({'Actual': y_test[\"stage1Measurement%d\"%(i)], 'Predicted': y_pred_stage1[\"Measurement%d\"%(i)]})\n",
    "\n",
    "    y_pred_stage2[\"Measurement%d\"%(i)] = lr_stage2[\"Measurement%d\"%(i)].predict(X_test[\"stage2Measurement%d\"%(i)])\n",
    "    y_actual_pred_stage2[\"Measurement%d\"%(i)] = pd.DataFrame({'Actual': y_test[\"stage2Measurement%d\"%(i)], 'Predicted': y_pred_stage2[\"Measurement%d\"%(i)]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Actual test value and Predicted value at stage 1\n",
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(15,1,figsize=(30,150))\n",
    "\n",
    "for i in range(15):\n",
    "    ax[i].plot(y_actual_pred_stage1[\"Measurement%d\"%(i)].index.tolist(),y_actual_pred_stage1[\"Measurement%d\"%(i)]['Actual'],\n",
    "               marker='.', linestyle=':', linewidth=0.5, label='Actual Test Measurement')\n",
    "    ax[i].plot(y_actual_pred_stage1[\"Measurement%d\"%(i)].index.tolist(),y_actual_pred_stage1[\"Measurement%d\"%(i)]['Predicted'],\n",
    "            marker='o', markersize=0.5, linestyle=':', label='Predicted Measurement')\n",
    "    ax[i].set_ylabel('Stage1.Output.Measurement%d'% (i))\n",
    "    ax[i].set_xlabel('Test Data Points')\n",
    "    ax[i].legend(loc='upper right');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Actual test value and Predicted value at stage 2\n",
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(15,1,figsize=(30,150))\n",
    "\n",
    "for i in range(15):\n",
    "    ax[i].plot(y_actual_pred_stage2[\"Measurement%d\"%(i)].index.tolist(),y_actual_pred_stage2[\"Measurement%d\"%(i)]['Actual'],\n",
    "               marker='.', linestyle=':', linewidth=0.5, label='Actual Test Measurement')\n",
    "    ax[i].plot(y_actual_pred_stage2[\"Measurement%d\"%(i)].index.tolist(),y_actual_pred_stage2[\"Measurement%d\"%(i)]['Predicted'],\n",
    "            marker='o', markersize=0.5, linestyle=':', label='Predicted Measurement')\n",
    "    ax[i].set_ylabel('Stage2.Output.Measurement%d'% (i))\n",
    "    ax[i].set_xlabel('Test Data Points')\n",
    "    ax[i].legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance: Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "\n",
    "mean_absolute_error_stage1 = {}\n",
    "mean_absolute_error_stage2 = {}\n",
    "mean_squared_error_stage1 = {}\n",
    "mean_squared_error_stage2 = {}\n",
    "root_mean_squared_error_stage1 = {}\n",
    "root_mean_squared_error_stage2 = {}\n",
    "\n",
    "for i in range(15):\n",
    "    mean_absolute_error_stage1[\"Measurement%d\"%(i)] = metrics.mean_absolute_error(y_test[\"stage1Measurement%d\"%(i)], y_pred_stage1[\"Measurement%d\"%(i)])\n",
    "    mean_absolute_error_stage2[\"Measurement%d\"%(i)] = metrics.mean_absolute_error(y_test[\"stage2Measurement%d\"%(i)], y_pred_stage2[\"Measurement%d\"%(i)])\n",
    "    \n",
    "    mean_squared_error_stage1[\"Measurement%d\"%(i)] = metrics.mean_squared_error(y_test[\"stage1Measurement%d\"%(i)], y_pred_stage1[\"Measurement%d\"%(i)])\n",
    "    mean_squared_error_stage2[\"Measurement%d\"%(i)] = metrics.mean_squared_error(y_test[\"stage2Measurement%d\"%(i)], y_pred_stage2[\"Measurement%d\"%(i)])\n",
    "    \n",
    "    root_mean_squared_error_stage1[\"Measurement%d\"%(i)] = np.sqrt(metrics.mean_squared_error(y_test[\"stage1Measurement%d\"%(i)], y_pred_stage1[\"Measurement%d\"%(i)]))\n",
    "    root_mean_squared_error_stage2[\"Measurement%d\"%(i)] = np.sqrt(metrics.mean_squared_error(y_test[\"stage2Measurement%d\"%(i)], y_pred_stage2[\"Measurement%d\"%(i)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer to Dataframe\n",
    "mean_absolute_error_stage1_df = pd.DataFrame.from_dict(list(mean_absolute_error_stage1.items()))\n",
    "mean_absolute_error_stage1_df.columns = ['Measurement', 'mean_absolute_error_stage1']\n",
    "mean_squared_error_stage1_df = pd.DataFrame.from_dict(list(mean_squared_error_stage1.items()))\n",
    "mean_squared_error_stage1_df.columns = ['Measurement', 'mean_squared_error_stage1']\n",
    "root_mean_squared_error_stage1_df = pd.DataFrame.from_dict(list(root_mean_squared_error_stage1.items()))\n",
    "root_mean_squared_error_stage1_df.columns = ['Measurement', 'root_mean_squared_error_stage1']\n",
    "\n",
    "Performance_stage1 = pd.concat([mean_absolute_error_stage1_df, mean_squared_error_stage1_df,root_mean_squared_error_stage1_df], axis=1)\n",
    "Performance_stage1 = Performance_stage1.loc[:,~Performance_stage1.columns.duplicated()]\n",
    "\n",
    "mean_absolute_error_stage2_df = pd.DataFrame.from_dict(list(mean_absolute_error_stage2.items()))\n",
    "mean_absolute_error_stage2_df.columns = ['Measurement', 'mean_absolute_error_stage2']\n",
    "mean_squared_error_stage2_df = pd.DataFrame.from_dict(list(mean_squared_error_stage2.items()))\n",
    "mean_squared_error_stage2_df.columns = ['Measurement', 'mean_squared_error_stage2']\n",
    "root_mean_squared_error_stage2_df = pd.DataFrame.from_dict(list(root_mean_squared_error_stage2.items()))\n",
    "root_mean_squared_error_stage2_df.columns = ['Measurement', 'root_mean_squared_error_stage2']\n",
    "\n",
    "Performance_stage2 = pd.concat([mean_absolute_error_stage2_df, mean_squared_error_stage2_df,root_mean_squared_error_stage2_df], axis=1)\n",
    "Performance_stage2 = Performance_stage2.loc[:,~Performance_stage2.columns.duplicated()]\n",
    "\n",
    "Performance = pd.concat([Performance_stage1, Performance_stage2], axis=1)\n",
    "Performance = Performance.loc[:,~Performance.columns.duplicated()]\n",
    "\n",
    "Performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lr performance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = Performance.plot.bar(x=['Measurement'], y=['root_mean_squared_error_stage1', 'root_mean_squared_error_stage2'],\n",
    "                          figsize=(30,10),fontsize=18)\n",
    "ax.set_xlabel('Measurement',fontsize=18)\n",
    "ax.legend(loc='upper right',fontsize=18)\n",
    "plt.title('Linear Regression Model Performance',fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### R-square\n",
    "lr_r2 = lr_stage1[\"Measurement0\"].score(X_train[\"stage1Measurement0\"], y_train[\"stage1Measurement0\"])\n",
    "print('R^2: {0}'.format(lr_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = abs(y_test[\"stage1Measurement0\"])-abs( y_pred_stage1[\"Measurement0\"])\n",
    "df_results = pd.DataFrame({'Actual': y_test[\"stage1Measurement0\"], 'Predicted': y_pred_stage1[\"Measurement0\"]})\n",
    "df_results['Residuals']=residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Assumption 1: linearity\n",
    "def linear_assumption(df_results):\n",
    "    \"\"\"\n",
    "    Linearity: Assumes that there is a linear relationship between the predictors and\n",
    "               the response variable. If not, either a quadratic term or another\n",
    "               algorithm should be used.\n",
    "    \"\"\"\n",
    "    print('Assumption 1: Linear Relationship between the Target and the Feature', '\\n')\n",
    "        \n",
    "    print('Checking with a scatter plot of actual vs. predicted.',\n",
    "           'Predictions should follow the diagonal line.')\n",
    "    \n",
    "    # Plotting the actual vs predicted values\n",
    "    sns.lmplot(x='Actual', y='Predicted', data=df_results, fit_reg=False, size=7)\n",
    "        \n",
    "    # Plotting the diagonal line\n",
    "    line_coords = np.arange(12, 13)\n",
    "    plt.plot(line_coords, line_coords,  # X and y points\n",
    "             color='darkorange', linestyle='--')\n",
    "    plt.title('Actual vs. Predicted')\n",
    "    plt.show()\n",
    "linear_assumption(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Assumption 2: Normality\n",
    "def normal_errors_assumption(residuals, p_value_thresh=0.05):\n",
    "    \"\"\"\n",
    "    Normality: Assumes that the error terms are normally distributed. If they are not,\n",
    "    nonlinear transformations of variables may solve this.\n",
    "               \n",
    "    This assumption being violated primarily causes issues with the confidence intervals\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.diagnostic import normal_ad\n",
    "    print('Assumption 2: The error terms are normally distributed', '\\n')\n",
    "    \n",
    "    print('Using the Anderson-Darling test for normal distribution')\n",
    "\n",
    "    # Performing the test on the residuals\n",
    "    p_value = normal_ad(residuals)[1]\n",
    "    print('p-value from the test - below 0.05 generally means non-normal:', p_value)\n",
    "    \n",
    "    # Reporting the normality of the residuals\n",
    "    if p_value < p_value_thresh:\n",
    "        print('Residuals are not normally distributed')\n",
    "    else:\n",
    "        print('Residuals are normally distributed')\n",
    "    \n",
    "    # Plotting the residuals distribution\n",
    "    plt.subplots(figsize=(12, 6))\n",
    "    plt.title('Distribution of Residuals')\n",
    "    sns.distplot(residuals)\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    if p_value > p_value_thresh:\n",
    "        print('Assumption satisfied')\n",
    "    else:\n",
    "        print('Assumption not satisfied')\n",
    "        print()\n",
    "        print('Confidence intervals will likely be affected')\n",
    "        print('Try performing nonlinear transformations on variables')\n",
    "normal_errors_assumption(residuals, p_value_thresh=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Assumption 3: autocorrelation\n",
    "def autocorrelation_assumption(df_results):\n",
    "    \"\"\"\n",
    "    Autocorrelation: Assumes that there is no autocorrelation in the residuals. If there is\n",
    "                     autocorrelation, then there is a pattern that is not explained due to\n",
    "                     the current value being dependent on the previous value.\n",
    "                     This may be resolved by adding a lag variable of either the dependent\n",
    "                     variable or some of the predictors.\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.stattools import durbin_watson\n",
    "    print('Assumption 3: No Autocorrelation', '\\n')\n",
    "    \n",
    "    # Calculating residuals for the Durbin Watson-tests\n",
    "\n",
    "    print('\\nPerforming Durbin-Watson Test')\n",
    "    print('Values of 1.5 < d < 2.5 generally show that there is no autocorrelation in the data')\n",
    "    print('0 to 2< is positive autocorrelation')\n",
    "    print('>2 to 4 is negative autocorrelation')\n",
    "    print('-------------------------------------')\n",
    "    durbinWatson = durbin_watson(df_results['Residuals'])\n",
    "    print('Durbin-Watson:', durbinWatson)\n",
    "    if durbinWatson < 1.5:\n",
    "        print('Signs of positive autocorrelation', '\\n')\n",
    "        print('Assumption not satisfied')\n",
    "    elif durbinWatson > 2.5:\n",
    "        print('Signs of negative autocorrelation', '\\n')\n",
    "        print('Assumption not satisfied')\n",
    "    else:\n",
    "        print('Little to no autocorrelation', '\\n')\n",
    "        print('Assumption satisfied')\n",
    "autocorrelation_assumption(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Assumption 4: Homoscedastricity\n",
    "def homoscedasticity_assumption(df_results):\n",
    "    \"\"\"\n",
    "    Homoscedasticity: Assumes that the errors exhibit constant variance\n",
    "    \"\"\"\n",
    "    print('Assumption 4: Homoscedasticity of Error Terms', '\\n')\n",
    "    \n",
    "    print('Residuals should have relative constant variance')\n",
    "        \n",
    "    \n",
    "    # Plotting the residuals\n",
    "    plt.subplots(figsize=(12, 6))\n",
    "    ax = plt.subplot(111)  # To remove spines\n",
    "    plt.scatter(x=df_results.index, y=df_results.Residuals, alpha=0.5)\n",
    "    plt.plot(np.repeat(0, df_results.index.max()), color='darkorange', linestyle='--')\n",
    "    ax.spines['right'].set_visible(False)  # Removing the right spine\n",
    "    ax.spines['top'].set_visible(False)  # Removing the top spine\n",
    "    plt.title('Residuals')\n",
    "    plt.show()  \n",
    "homoscedasticity_assumption(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Bayesian Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brr_stage1 = {} # Model\n",
    "brr_stage2 = {}\n",
    "coeff_brr_stage1 = {} # Coefficient\n",
    "coeff_brr_stage2 = {}\n",
    "for i in range(15):\n",
    "    brr_stage1[\"Measurement%d\"%(i)] = BayesianRidge(compute_score=True)\n",
    "    brr_stage1[\"Measurement%d\"%(i)].fit(X_train[\"stage1Measurement%d\"%(i)], y_train[\"stage1Measurement%d\"%(i)])\n",
    "    \n",
    "    brr_stage2[\"Measurement%d\"%(i)] = BayesianRidge(compute_score=True)\n",
    "    brr_stage2[\"Measurement%d\"%(i)].fit(X_train[\"stage2Measurement%d\"%(i)], y_train[\"stage2Measurement%d\"%(i)])\n",
    "    \n",
    "    coeff_brr_stage1[\"Measurement%d\"%(i)] = pd.DataFrame(brr_stage1[\"Measurement%d\"%(i)].coef_, TrainingSet_stage1[\"Measurement%d\"%(i)][C_cols_Stage1].columns, columns=['Coefficient']) \n",
    "    coeff_brr_stage2[\"Measurement%d\"%(i)] = pd.DataFrame(brr_stage2[\"Measurement%d\"%(i)].coef_, TrainingSet_stage2[\"Measurement%d\"%(i)][C_cols_Stage2].columns, columns=['Coefficient'])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stage1 = {} # Predicted value\n",
    "y_pred_stage2 = {}\n",
    "y_actual_pred_stage1 = {} # Compare Actual value and Predicted value\n",
    "y_actual_pred_stage2 = {}\n",
    "\n",
    "for i in range(15):\n",
    "    y_pred_stage1[\"Measurement%d\"%(i)] = brr_stage1[\"Measurement%d\"%(i)].predict(X_test[\"stage1Measurement%d\"%(i)])\n",
    "    y_actual_pred_stage1[\"Measurement%d\"%(i)] = pd.DataFrame({'Actual': y_test[\"stage1Measurement%d\"%(i)], 'Predicted': y_pred_stage1[\"Measurement%d\"%(i)]})\n",
    "\n",
    "    y_pred_stage2[\"Measurement%d\"%(i)] = brr_stage2[\"Measurement%d\"%(i)].predict(X_test[\"stage2Measurement%d\"%(i)])\n",
    "    y_actual_pred_stage2[\"Measurement%d\"%(i)] = pd.DataFrame({'Actual': y_test[\"stage2Measurement%d\"%(i)], 'Predicted': y_pred_stage2[\"Measurement%d\"%(i)]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare Actual test value and Predicted value at stage 1\n",
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(15,1,figsize=(30,150))\n",
    "\n",
    "for i in range(15):\n",
    "    ax[i].plot(y_actual_pred_stage1[\"Measurement%d\"%(i)].index.tolist(),y_actual_pred_stage1[\"Measurement%d\"%(i)]['Actual'],\n",
    "               marker='.', linestyle=':', linewidth=0.5, label='Actual Test Measurement')\n",
    "    ax[i].plot(y_actual_pred_stage1[\"Measurement%d\"%(i)].index.tolist(),y_actual_pred_stage1[\"Measurement%d\"%(i)]['Predicted'],\n",
    "            marker='o', markersize=0.5, linestyle=':', label='Predicted Measurement')\n",
    "    ax[i].set_ylabel('Stage1.Output.Measurement%d'% (i))\n",
    "    ax[i].set_xlabel('Test Data Points')\n",
    "    ax[i].legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare Actual test value and Predicted value at stage 2\n",
    "fig = plt.figure()\n",
    "fig, ax = plt.subplots(15,1,figsize=(30,150))\n",
    "\n",
    "for i in range(15):\n",
    "    ax[i].plot(y_actual_pred_stage2[\"Measurement%d\"%(i)].index.tolist(),y_actual_pred_stage2[\"Measurement%d\"%(i)]['Actual'],\n",
    "               marker='.', linestyle=':', linewidth=0.5, label='Actual Test Measurement')\n",
    "    ax[i].plot(y_actual_pred_stage2[\"Measurement%d\"%(i)].index.tolist(),y_actual_pred_stage2[\"Measurement%d\"%(i)]['Predicted'],\n",
    "            marker='o', markersize=0.5, linestyle=':', label='Predicted Measurement')\n",
    "    ax[i].set_ylabel('Stage2.Output.Measurement%d'% (i))\n",
    "    ax[i].set_xlabel('Test Data Points')\n",
    "    ax[i].legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance: Mean Absolute Error, Mean Squared Error, Root Mean Squared Error\n",
    "\n",
    "mean_absolute_error_stage1 = {}\n",
    "mean_absolute_error_stage2 = {}\n",
    "mean_squared_error_stage1 = {}\n",
    "mean_squared_error_stage2 = {}\n",
    "root_mean_squared_error_stage1 = {}\n",
    "root_mean_squared_error_stage2 = {}\n",
    "\n",
    "for i in range(15):\n",
    "    mean_absolute_error_stage1[\"Measurement%d\"%(i)] = metrics.mean_absolute_error(y_test[\"stage1Measurement%d\"%(i)], y_pred_stage1[\"Measurement%d\"%(i)])\n",
    "    mean_absolute_error_stage2[\"Measurement%d\"%(i)] = metrics.mean_absolute_error(y_test[\"stage2Measurement%d\"%(i)], y_pred_stage2[\"Measurement%d\"%(i)])\n",
    "    \n",
    "    mean_squared_error_stage1[\"Measurement%d\"%(i)] = metrics.mean_squared_error(y_test[\"stage1Measurement%d\"%(i)], y_pred_stage1[\"Measurement%d\"%(i)])\n",
    "    mean_squared_error_stage2[\"Measurement%d\"%(i)] = metrics.mean_squared_error(y_test[\"stage2Measurement%d\"%(i)], y_pred_stage2[\"Measurement%d\"%(i)])\n",
    "    \n",
    "    root_mean_squared_error_stage1[\"Measurement%d\"%(i)] = np.sqrt(metrics.mean_squared_error(y_test[\"stage1Measurement%d\"%(i)], y_pred_stage1[\"Measurement%d\"%(i)]))\n",
    "    root_mean_squared_error_stage2[\"Measurement%d\"%(i)] = np.sqrt(metrics.mean_squared_error(y_test[\"stage2Measurement%d\"%(i)], y_pred_stage2[\"Measurement%d\"%(i)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer to Dataframe\n",
    "mean_absolute_error_stage1_df = pd.DataFrame.from_dict(list(mean_absolute_error_stage1.items()))\n",
    "mean_absolute_error_stage1_df.columns = ['Measurement', 'mean_absolute_error_stage1']\n",
    "mean_squared_error_stage1_df = pd.DataFrame.from_dict(list(mean_squared_error_stage1.items()))\n",
    "mean_squared_error_stage1_df.columns = ['Measurement', 'mean_squared_error_stage1']\n",
    "root_mean_squared_error_stage1_df = pd.DataFrame.from_dict(list(root_mean_squared_error_stage1.items()))\n",
    "root_mean_squared_error_stage1_df.columns = ['Measurement', 'root_mean_squared_error_stage1']\n",
    "\n",
    "Performance_stage1 = pd.concat([mean_absolute_error_stage1_df, mean_squared_error_stage1_df,root_mean_squared_error_stage1_df], axis=1)\n",
    "Performance_stage1 = Performance_stage1.loc[:,~Performance_stage1.columns.duplicated()]\n",
    "\n",
    "mean_absolute_error_stage2_df = pd.DataFrame.from_dict(list(mean_absolute_error_stage2.items()))\n",
    "mean_absolute_error_stage2_df.columns = ['Measurement', 'mean_absolute_error_stage2']\n",
    "mean_squared_error_stage2_df = pd.DataFrame.from_dict(list(mean_squared_error_stage2.items()))\n",
    "mean_squared_error_stage2_df.columns = ['Measurement', 'mean_squared_error_stage2']\n",
    "root_mean_squared_error_stage2_df = pd.DataFrame.from_dict(list(root_mean_squared_error_stage2.items()))\n",
    "root_mean_squared_error_stage2_df.columns = ['Measurement', 'root_mean_squared_error_stage2']\n",
    "\n",
    "Performance_stage2 = pd.concat([mean_absolute_error_stage2_df, mean_squared_error_stage2_df,root_mean_squared_error_stage2_df], axis=1)\n",
    "Performance_stage2 = Performance_stage2.loc[:,~Performance_stage2.columns.duplicated()]\n",
    "\n",
    "Performance = pd.concat([Performance_stage1, Performance_stage2], axis=1)\n",
    "Performance = Performance.loc[:,~Performance.columns.duplicated()]\n",
    "\n",
    "Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='brr performance'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = Performance.plot.bar(x=['Measurement'], y=['root_mean_squared_error_stage1', 'root_mean_squared_error_stage2'],\n",
    "                          figsize=(30,10),fontsize=18)\n",
    "ax.set_xlabel('Measurement',fontsize=18)\n",
    "ax.legend(loc='upper right',fontsize=18)\n",
    "plt.title('Bayesian Ridge Regression Model Performance',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Coefficients'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of Bayesian Ridge Regression model is similar with performance of Linear Regression model \n",
    "# Bayesian Ridge Regression model give shrinkage to those coefficient of high VIF variables\n",
    "# Take Measurement0 for example, see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of Linear Regression, eg: Measurement0\n",
    "coeff_lr_stage1[\"Measurement0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of Bayesian Ridge Regression, eg: Measurement0\n",
    "coeff_brr_stage1[\"Measurement0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    joblib.dump(lr_stage1[\"Measurement%d\"%(i)],'lr_stage1_Measurement%d.pkl'%(i))\n",
    "    joblib.dump(lr_stage2[\"Measurement%d\"%(i)],'lr_stage2_Measurement%d.pkl'%(i))\n",
    "    joblib.dump(brr_stage1[\"Measurement%d\"%(i)],'brr_stage1_Measurement%d.pkl'%(i))\n",
    "    joblib.dump(brr_stage2[\"Measurement%d\"%(i)],'brr_stage2_Measurement%d.pkl'%(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
